{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pylab import mpl\n",
    "import random\n",
    "import keras\n",
    "from math import sqrt\n",
    "import tensorflow as tf\n",
    " \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from collections import deque\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense,LSTM,BatchNormalization,Dropout,SimpleRNN,Activation,Input,Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.losses import mape\n",
    "from keras import optimizers\n",
    "from scipy.io import loadmat,savemat\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\"横波反演数据.xlsx\",sheet_name='yq3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['RT-电阻率']=np.log10(dataset['RT-电阻率'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunms=['CNL-中子','DEN-密度','GR-自然伽马','VP-纵波速度','RT-电阻率']     \n",
    "scaler=MinMaxScaler()\n",
    "scaler1=MinMaxScaler()\n",
    "for col in colunms:\n",
    "    dataset[col]=scaler.fit_transform(dataset[col].values.reshape(-1,1))\n",
    "dataset['VS-横波速度']=scaler1.fit_transform(dataset['VS-横波速度'].values.reshape(-1,1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.loc[:,['CNL-中子','DEN-密度','GR-自然伽马','VP-纵波速度','RT-电阻率']]\n",
    "y=dataset['VS-横波速度']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=666,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(x,y,days):\n",
    "    features=[]\n",
    "    targets=[]\n",
    "    \n",
    "    x=scaler.fit_transform(x.iloc[:,:])\n",
    "    deq=deque(maxlen=days)\n",
    "    for i in x:\n",
    "        deq.append(list(i))\n",
    "        if days==len(deq):\n",
    "            features.append(list(deq))\n",
    "            \n",
    "            \n",
    "    x=features[:]        \n",
    "    targets=y.values[days-1:]\n",
    "    \n",
    "    \n",
    "    return np.array(x),np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,train_labels=windows(X_train,y_train,3)\n",
    "test_dataset,test_labels=windows(X_test,y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=np.expand_dims(train_dataset,axis=3)\n",
    "test1=np.expand_dims(test_dataset,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_dataset(X, y, train=True, buffer_size=1000, batch_size=128):\n",
    "    batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "    if train: \n",
    "        return batch_data.cache().shuffle(buffer_size).batch(batch_size)\n",
    "    else: \n",
    "        return batch_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_dataset = create_batch_dataset(train_dataset, train_labels)\n",
    "test_batch_dataset = create_batch_dataset(test_dataset, test_labels, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Conv2D(keras.layers.Layer):\n",
    "    def __init__(self, filters=None, num_heads=None, gamma=0.01, activation='relu', return_attention_scores=False, trainable=True):\n",
    "        super().__init__(trainable=trainable)\n",
    "        self.gamma = tf.Variable(initial_value=gamma, trainable=True, name='gamma')\n",
    "        self.f = None\n",
    "        self.g = None\n",
    "        self.h = None\n",
    "        self.v = None\n",
    "        self.attention = None\n",
    "        self.num_heads = num_heads\n",
    "        self.c = filters\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        if self.c is None:\n",
    "            self.c = input_shape[-1]\n",
    "\n",
    "        if self.num_heads is None:\n",
    "            self.num_heads = input_shape[-1]\n",
    "\n",
    "        self.f = self.block(self.num_heads) # [n, w*h, heads]\n",
    "        self.g = self.block(self.num_heads) # [n, w*h, heads]\n",
    "        self.h = self.block(self.num_heads) # [n, w*h, heads]\n",
    "\n",
    "        # output feature maps -> [n, w, h, filters]\n",
    "        self.v = layers.Conv2D(self.c, 1, 1, activation=self.activation)\n",
    "\n",
    "    @staticmethod\n",
    "    def block(head):\n",
    "        return keras.Sequential([\n",
    "            layers.Conv2D(head, 1, 1),   # [n, w, h, heads] 1*1conv\n",
    "            layers.Reshape((-1, head)),  # [n, w*h, heads]\n",
    "            ])\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        f = self.f(inputs)    # [n, w*h, heads]\n",
    "        g = self.g(inputs)    # [n, w*h, heads]\n",
    "        h = self.h(inputs)    # [n, w*h, heads]\n",
    "        s = tf.matmul(f, g, transpose_b=True)   # [n, w*h, heads] @ [n, heads, w*h] = [n, w*h, w*h]\n",
    "        self.attention = tf.nn.softmax(s, axis=-1)\n",
    "        context_wh = tf.matmul(self.attention, h)  # [n, w*h, w*h] @ [n, w*h, heads] = [n, w*h, heads]\n",
    "        d = inputs.shape        # [n, w, h, channels]\n",
    "        cs = context_wh.shape   # [n, w*h, heads]\n",
    "        context = self.gamma * tf.reshape(context_wh, [-1, d[1], d[2], cs[-1]])    # [n, w, h, c]\n",
    "        o = self.v(context) + inputs   # residual -> [n, w, h, filters]\n",
    "\n",
    "        return tf.reshape(o,[-1,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_model4():\n",
    "    inputs = Input(train1.shape[-3:])\n",
    "\n",
    "    x=Attention_Conv2D(1, activation='relu', num_heads=32, return_attention_scores=True)(inputs)\n",
    "    x=Dropout(0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (2,5), padding=\"same\",activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.01))(x)  #, padding = 'same'\n",
    "    x = Dropout(0.1)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Conv2D(10, (2,1), padding=\"same\", activation=\"relu\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "      \n",
    "#     lstm_out = tf.keras.layers.Bidirectional(LSTM(32,return_sequences=True,kernel_regularizer=keras.regularizers.l2(0.01)))(x[:,:,:,0])\n",
    "#     lstm_out = Dropout(0.1)(lstm_out)\n",
    "#     lstm_out = BatchNormalization()(lstm_out)\n",
    "#     lstm_out = tf.keras.layers.Bidirectional(LSTM(16,return_sequences=True,kernel_regularizer=keras.regularizers.l2(0.01)))(lstm_out)\n",
    "#     lstm_out = Dropout(0.1)(lstm_out)\n",
    "#     lstm_out = BatchNormalization()(lstm_out)\n",
    "    attention_mul = Flatten()(x)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    model.compile(loss=['MSE'],optimizer=tf.keras.optimizers.Adam(learning_rate=0.004, beta_1=0.9),)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(mul_head,hid_dim0):\n",
    "    inputs = Input(train1.shape[-3:])\n",
    "    \n",
    "\n",
    "    \n",
    "    x=Attention_Conv2D(1, activation='relu', num_heads=mul_head, return_attention_scores=True)(inputs)\n",
    "    x=Dropout(0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(hid_dim0, (3,5), padding=\"same\",activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.01))(inputs)  #, padding = 'same'\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Conv2D(hid_dim1, (3,5), padding=\"same\",activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.01))(x)  #, padding = 'same'\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Conv2D(hid_dim2, (3,5), padding=\"same\",activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.01))(x)  #, padding = 'same'\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    \n",
    "#     lstm_out = tf.keras.layers.LSTM(hid_dim1,return_sequences=True,kernel_regularizer=keras.regularizers.l2(0.01))(x[:,:,:,0])\n",
    "#     lstm_out = Dropout(0.1)(lstm_out)\n",
    "#     lstm_out = BatchNormalization()(lstm_out)\n",
    "#     lstm_out = tf.keras.layers.LSTM(hid_dim2,return_sequences=True)(lstm_out)\n",
    "#     lstm_out = Dropout(0.1)(lstm_out)\n",
    "#     lstm_out = BatchNormalization()(lstm_out)\n",
    "    lstm_out = Dense(10,activation=\"relu\")(x)  # 全连接层数 Number of fully connected layers\n",
    "    attention_mul = Flatten()(lstm_out)\n",
    "\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_params(train1.shape[-3:],train_batch_dataset,test_batch_dataset,train_labels,test_labels,**result):\n",
    "    model=build_model(result['mul_head'],result['cnn_layers'])\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(result['lr']), metrics=['mean_squared_error'])\n",
    "    model.fit(train_batch_dataset,epochs=result['epochs'],verbose=0,\n",
    "                    validation_data=test_batch_dataset)\n",
    "    yhat = model.predict(train_batch_dataset, verbose=0) #预测\n",
    "    \n",
    "    return np.mean(np.square((yhat-train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 = 0.036260393651294506 [57, 50, 42, 28, 0.0064724642197745725]\n",
      "iteration 2 = 0.036260393651294506 [57, 50, 42, 28, 0.0064724642197745725]\n",
      "iteration 3 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 4 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 5 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 6 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 7 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 8 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 9 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n",
      "iteration 10 = 0.035075349247503454 [56, 53, 41, 27, 0.006356192688847642]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "fit_with_partial = partial(fit_params, train1.shape[-3:], train_batch_dataset,test_batch_dataset)\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'mul_head':(50,70), 'cnn_layers':(50, 60), 'batch_size':(42, 50), 'epochs': (20,30), 'lr': (0.006,0.007)}\n",
    "\n",
    "# Setting up the optimiser\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2, \n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Start the parameter search\n",
    "optimizer.maximize(init_points=5, n_iter=4)\n",
    "\n",
    "# Print the results for each iteration\n",
    "for i, res in enumerate(optimizer.res):\n",
    "     print (\"iteration\",i+1,\"=\",optimizer.res,[reslust[i] if i==dim-1 else int(reslust[i]) for i in range(len(relust))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.rcParams['font.sans-serif'] = ['SimHei'] #防止中文乱码\n",
    "    plt.rcParams['axes.unicode_minus']=False\n",
    "    plt.figure()\n",
    "    plt.plot(trace)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('适应度值')\n",
    "    plt.title(\"Bayes适应度曲线图\")\n",
    "#     plt.savefig('Bayes适应度曲线.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-7a8c8a1e13f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "result=result[-1:,:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(result):\n",
    "    inputs = Input(train1.shape[-3:])\n",
    "    \n",
    "    x=Attention_Conv2D(1, activation='relu', num_heads=int(result['mul_head']), return_attention_scores=True)(inputs)\n",
    "    x=Dropout(0.1)(x)\n",
    "    x = Conv2D(int(result['cnn_layers']), (3,5), padding=\"same\",activation=\"relu\")(inputs)  #, padding = 'same'\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "\n",
    "    lstm_out = Dense(10,activation=\"relu\")(x) \n",
    "    attention_mul = Flatten()(lstm_out)\n",
    "\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(result['lr'], beta_1=0.5),#学习率  learning rate\n",
    "                  loss=\"mean_squared_error\")#回归问题，损失函数使用均方误差  Regression problem, loss function using mean square error\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_117 (InputLayer)       [(None, 3, 5, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 3, 5, 27)          432       \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 3, 5, 27)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 3, 5, 27)          108       \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 3, 5, 10)          280       \n",
      "_________________________________________________________________\n",
      "flatten_111 (Flatten)        (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 971\n",
      "Trainable params: 917\n",
      "Non-trainable params: 54\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 2/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 3/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 4/27\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 5/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 6/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 7/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 8/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 9/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 10/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 11/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 12/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 13/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 14/27\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 15/27\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 16/27\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 17/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 18/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 19/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 20/27\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 21/27\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 22/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 23/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 24/27\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 25/27\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 26/27\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 27/27\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batch_dataset,\n",
    "                    epochs=result['epochs'],\n",
    "                    validation_data=test_batch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2值为： 0.9398536638589423\n"
     ]
    }
   ],
   "source": [
    "score1=r2_score(train_labels,pred)\n",
    "print('r^2值为：',score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
